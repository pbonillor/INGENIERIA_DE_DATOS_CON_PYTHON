# INGENIERIA DE DATOS CON PYTHON

En el mundo actual, la toma de decisiones informadas por datos es fundamental para el éxito en diversos campos profesionales. La abundancia de tecnologías para la captura de datos ofrece enormes posibilidades, pero la habilidad de convertir estos datos en conocimientos valiosos para la toma de decisiones requiere un conjunto específico de herramientas y habilidades. En este contexto, el curso de Ingeniería de Datos con Python proporciona una sólida base en modelado y tecnología para respaldar la toma de decisiones basadas en datos ("data-driven").

# ¿Cuales son los objetivos del curso?

Al completar el curso, los participantes desarrollarán las siguientes capacidades:

  * Exploración, análisis y visualización de datos: Dominarán técnicas para explorar y visualizar diversos conjuntos de datos, lo que les permitirá comprender mejor la información contenida en ellos.

  * Preprocesamiento de datos: Aprenderán a realizar el preprocesamiento de grandes cantidades de datos utilizando algoritmos y técnicas estadísticas, lo que facilitará su posterior análisis y modelado.

  * Desarrollo de algoritmos de Aprendizaje de Máquina: Adquirirán habilidades para implementar tanto algoritmos supervisados como no supervisados de Aprendizaje de Máquina, lo que les permitirá extraer información significativa de los datos.

  * Implementación de proyectos de ciencia de datos: Estarán capacitados para abordar proyectos que requieran el uso de ciencia de datos en la toma de decisiones y la extracción de conocimiento a partir de los datos.

# Requisitos:
Para realizar este curso, son necesarios conocimientos básicos de computación

# Modalidad: 
* 60 horas, 6 semanas, 10 horas semanales, presencial en aula virtual (En directo por Google Meet, se le invitará a las reuniones correspondientes).
* También necesitarás otras 60 horas como mínimo de trabajo en casa obligatorio para entregar los ejercicios, horas de estudio, proyectos, trabajos obligatorios y demás.
* Nuestros grupos son reducidos, máximo 10-11 alumnos (en función del aula), con esto conseguimos la mejor atención posible y que esas horas lectivas sean de la máxima calidad y más que suficientes para cubrir un temario muy extenso y completo.

# Requisitos de aprobación:
* 75% (al menos 45 horas de 60) de asistencia a las clases en linea. Se registrará la asistencia a cada clase.
* Completar y reportar las 60 horas de ejercicios enviados a lo largo del curso.
* Entregar proyecto que se asignará el Sabado 18 de Noviembre (ultima clase presencial en aula virtual) y que debe ser enviado por email al profesor.

# CONTENIDO
## [MODULO I - INTRODUCCIÓN Y REPASO GENERAL DE CONCEPTOS]
  * Que es la Ingeniería de Datos.
  * Fases en un proyecto de Ingeniería de Datos.
  * Herramienta de trabajo Google Colab (Google Colaboratory)
  * Fundamentos generales de Python para la Ingeniría de Datos.
    * [Introducción a Python](https://colab.research.google.com/github/bonillo-software/INGENIERIA_DE_DATOS_CON_PYTHON/blob/main/MODULO_I/python.ipynb)
    * [Numpy](https://colab.research.google.com/github/bonillo-software/INGENIERIA_DE_DATOS_CON_PYTHON/blob/main/MODULO_I/numpy.ipynb)
    * [Pandas](https://colab.research.google.com/github/bonillo-software/INGENIERIA_DE_DATOS_CON_PYTHON/blob/main/MODULO_I/pandas.ipynb)
    * Pyspark
    * Scala
  * Apache Spark y su integración con Scala
  * Ejercicio 1
* 
## [MODULO II - PROCESAMIENTO DE DATOS CON DATABRICKS]
  * Databricks Community Edition.
  * Creación de una cuenta en Databricks Community Edition.
  * Entorno de trabajo en Databricks.
  * Creación de un cluster en Databricks.
  * Creación de un notebook en Databricks.
  * Importación de datos a Databricks.
  * Ejercicio 2

## [MODULO III - RDD EN SPARK UTILIZANDO SCALA Y PYSPARK]
  * Spark Sessión.
  * ¿Qué es un RDD?
  * Diferentes formas de crear un RDD en Scala y pyspark.
  * Transformaciones en un RDD.Función map.Función flatMap.Función filter.Función coalesce.Función repartition.Función reduceByKey
  * Acciones en un RDD.Función reduce.Función count.Función collect.Funciones take, max y saveAsTextFile
  * Almacenamiento en caché
  * Particionado
  * Mezcla de datos (shuffling)
  * Broadcast variable
  * Accumulators
  * Ejercicio 3.

## [MODULO IV - SPARK SQL]
  * Creación de un DataFrame a partir de un RDD en Scala Y Pyspark.
  * Creación de un DataFrame a partir de fuentes de datos en Scala y Pyspark.
  * Trabajo con columnas.
  * Funciones select y selectExpr.Funciones filter y where.Funciones distinct y dropDuplicates.Funciones withColumn y withColumnRenamed.Funciones drop, sample.
  * Trabajo con datos incorrectos o faltantes.
  * Acciones sobre un DataFrame en Spark SQL.
  * Escritura de DataFrames.
  * Persistencia de DataFrames.
  * Agregaciones.Funciones count, countDistinct y approx_count_distinct.Funciones min y max.Funciones sum, sum_distinct y avg.
  * Agregación con agrupación.
  * Varias agregaciones por grupo.
  * Agregación con pivote.
  * Joins.
  * Expresión join y tipos de join.
  * Inner Join, Left Outer Join, Right Outer Join, Full Outer Join, Left Anti Join, Left Semi Join, Cross Join.
  * Manejo de nombres de columna duplicados.
  * Shuffle Hash Join y Broadcast Hash Join.
  * Ejercicio 4

## MODULO V - FUNCIONES EN SPARKSQL CON SCALA Y PYSPARK
  * Funciones de fecha y hora.
  * Funciones para trabajo con strings.
  * Funciones para trabajo con colecciones.
  * Funciones when, coalesce y lit.
  * Funciones definidas por el usuario (UDF).
  * Funciones de ventana.
  * Catalyst Optimizer.
 
## MODULO VI – PROYECTO FIN DE MÁSTER
  * Desarrollo de un caso de uso, en el que el alumno debe poner en práctica lo visto 
  
## Bibliografia

McKinney, Wes. (2017). "Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython". O'Reilly Media.
Raschka, Sebastian, & Mirjalili, Vahid. (2019). "Python Machine Learning". Packt Publishing.
Chambers, John, & Zaharia, Matei. (2018). "Spark: The Definitive Guide: Big Data Processing Made Simple". O'Reilly Media.
Ghosh, Debjani. (2020). "Mastering PySpark". Packt Publishing.
Zeitler, Matthew. (2019). "Mastering Large Datasets with Python". Packt Publishing.
Zhang, Xiangrui et al. (2015). "Learning Spark: Lightning-Fast Big Data Analysis". O'Reilly Media.